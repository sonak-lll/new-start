{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pretrained된 모델로 prediction만 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, DistributedSampler, random_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from pytorch_lightning.core.lightning import LightningModule \n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.metrics.functional import accuracy, precision, recall\n",
    "from transformers import AdamW, BertForSequenceClassification, AdamW, BertConfig, AutoTokenizer, BertTokenizer, TrainingArguments\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>ratings</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>search</th>\n",
       "      <th>keyword</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>김성주</td>\n",
       "      <td>5</td>\n",
       "      <td>9시간 전</td>\n",
       "      <td>가편하게 산책과 등산을 할 수 있는 곳</td>\n",
       "      <td>계룡산국립공원수통골지구</td>\n",
       "      <td>water_barrel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>서알콩</td>\n",
       "      <td>5</td>\n",
       "      <td>1일 전</td>\n",
       "      <td>커피 한잔하기 딱 좋은 거리에 용</td>\n",
       "      <td>계룡산국립공원수통골지구</td>\n",
       "      <td>water_barrel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>윤설희</td>\n",
       "      <td>5</td>\n",
       "      <td>2일 전</td>\n",
       "      <td>비 오고 난 수통골</td>\n",
       "      <td>계룡산국립공원수통골지구</td>\n",
       "      <td>water_barrel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>이상훈</td>\n",
       "      <td>4</td>\n",
       "      <td>2일 전</td>\n",
       "      <td>가족 나들이하기 정말 좋은 곳 국립이라 관리도 잘 돼있네요</td>\n",
       "      <td>계룡산국립공원수통골지구</td>\n",
       "      <td>water_barrel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>송순이공주</td>\n",
       "      <td>5</td>\n",
       "      <td>2일 전</td>\n",
       "      <td>동네라서 자주 가는데 갈 때마다 좋은 곳이에요 이에는 뱀이 나와서 좀 놀랐어요</td>\n",
       "      <td>계룡산국립공원수통골지구</td>\n",
       "      <td>water_barrel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>680</td>\n",
       "      <td>김태규</td>\n",
       "      <td>4</td>\n",
       "      <td>4년 전</td>\n",
       "      <td>완만한 산책 등산 먹거리 좋아요</td>\n",
       "      <td>수통골유원지</td>\n",
       "      <td>water_barrel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>681</td>\n",
       "      <td>김뚱이</td>\n",
       "      <td>5</td>\n",
       "      <td>4년 전</td>\n",
       "      <td>가깝고 깨끗하게 정리도 잘 되어 있어서 좋아요</td>\n",
       "      <td>수통골유원지</td>\n",
       "      <td>water_barrel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>682</td>\n",
       "      <td>이시형</td>\n",
       "      <td>5</td>\n",
       "      <td>4년 전</td>\n",
       "      <td>가끔 산책하러 가는 수통골이에요</td>\n",
       "      <td>수통골유원지</td>\n",
       "      <td>water_barrel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>683</td>\n",
       "      <td>Park Sangbae</td>\n",
       "      <td>4</td>\n",
       "      <td>4년 전</td>\n",
       "      <td>등산을 목적으로 한다면 다녀올만함 여러 코스가 있으니 취향과 체력에 맞춰서 다녀오시...</td>\n",
       "      <td>수통골유원지</td>\n",
       "      <td>water_barrel</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>684</td>\n",
       "      <td>hyun seung shin</td>\n",
       "      <td>3</td>\n",
       "      <td>4년 전</td>\n",
       "      <td>좋은 산책길 간단한 등산도 가능</td>\n",
       "      <td>수통골유원지</td>\n",
       "      <td>water_barrel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>685 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0               name  ratings   date  \\\n",
       "0             0               김성주         5  9시간 전   \n",
       "1             1               서알콩         5   1일 전   \n",
       "2             2               윤설희         5   2일 전   \n",
       "3             3               이상훈         4   2일 전   \n",
       "4             4             송순이공주         5   2일 전   \n",
       "..          ...                ...      ...    ...   \n",
       "680         680               김태규         4   4년 전   \n",
       "681         681               김뚱이         5   4년 전   \n",
       "682         682               이시형         5   4년 전   \n",
       "683         683      Park Sangbae         4   4년 전   \n",
       "684         684   hyun seung shin         3   4년 전   \n",
       "\n",
       "                                               comment        search  \\\n",
       "0                                가편하게 산책과 등산을 할 수 있는 곳  계룡산국립공원수통골지구   \n",
       "1                                   커피 한잔하기 딱 좋은 거리에 용  계룡산국립공원수통골지구   \n",
       "2                                           비 오고 난 수통골  계룡산국립공원수통골지구   \n",
       "3                     가족 나들이하기 정말 좋은 곳 국립이라 관리도 잘 돼있네요  계룡산국립공원수통골지구   \n",
       "4          동네라서 자주 가는데 갈 때마다 좋은 곳이에요 이에는 뱀이 나와서 좀 놀랐어요  계룡산국립공원수통골지구   \n",
       "..                                                 ...           ...   \n",
       "680                                  완만한 산책 등산 먹거리 좋아요        수통골유원지   \n",
       "681                          가깝고 깨끗하게 정리도 잘 되어 있어서 좋아요        수통골유원지   \n",
       "682                                  가끔 산책하러 가는 수통골이에요        수통골유원지   \n",
       "683  등산을 목적으로 한다면 다녀올만함 여러 코스가 있으니 취향과 체력에 맞춰서 다녀오시...        수통골유원지   \n",
       "684                                  좋은 산책길 간단한 등산도 가능        수통골유원지   \n",
       "\n",
       "          keyword  label  \n",
       "0    water_barrel      1  \n",
       "1    water_barrel      1  \n",
       "2    water_barrel      1  \n",
       "3    water_barrel      1  \n",
       "4    water_barrel      1  \n",
       "..            ...    ...  \n",
       "680  water_barrel      1  \n",
       "681  water_barrel      1  \n",
       "682  water_barrel      1  \n",
       "683  water_barrel     -1  \n",
       "684  water_barrel      1  \n",
       "\n",
       "[685 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = pd.read_csv('/home/aiffel-dj57/project/labeled_water_barrel.csv')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/kcbert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"beomi/kcbert-base\",\n",
    "    num_labels = 2, \n",
    "                    \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30000, 768)\n",
      "bert.embeddings.position_embeddings.weight                (300, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_data(sentences):\n",
    "\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "    MAX_LEN = 64\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    \n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "        \n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentences(sentences):\n",
    " \n",
    "    # 평가모드로 변경!!!!!\n",
    "    model.eval()\n",
    "\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09950283 0.21006171]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['기대를 하지 않고 가면 충분히 즐길만합니다.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16729078  0.17005226]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['야간 개장을 시작하여 선선하게 둘러볼 수 있어 더 좋은 것 같다.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18517739 0.16900083]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['놀이기구 운영을 너무 천천히 해요 기구 타려면 너무 오래 기다려야 해요.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01652993  0.40031958]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['아이들의 놀이터 하지만 어른들의 새치기 주말은 피하시길다.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18033575 -0.1233479 ]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['좋긴 한데 사람이 너무 많아서'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.34756047 -0.18381375]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['동네라서 자주 가는데 갈 때마다 좋은 곳이에요 이에는 뱀이 나와서 좀 놀랐어요'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01437217 0.332919  ]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['간단하게 발족 욕을 할 수 있는 족욕 쟁입니다 일부러 들릴만한 곳은 아니지만 쉬어가기에는 좋은 것 같네요 물을 자주 갈아주는 것 같지는 않네요'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1033605   0.02618557]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['현재 코로나 때에 물다 빠져 있고 체험 불가'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) # 긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.19290826  0.08791158]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['유성온천 근처의 산책과 함께 족욕을 즐길 수 있는 곳 사람이 많을 때는 물이 약간 깨끗하지 않음'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.09999039  0.14928955]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['산책로가 잘되어 있어 산책하기 좋습니다 등산로도 있는데 등산하신다면 신발과 배낭 그리고 물은 챙기시는 게 좋을 거 같습니다 등산로 지형은 간혹 가파른 곳이 있어 안전사고에 주의가 필요합니다'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 체크 \n",
    "\n",
    "1. label num = 3 을 넣고 수행해봤더니 0으로만 계산되어 나왔다.\n",
    "2. 긍정-부정이 같이 있으면 0(부정)으로 확인함을 알 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영화 데이터로 파인튜닝한 모델을 불러와 prediction 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "model2 = BertForSequenceClassification.from_pretrained(\"./sentiment-analysis/checkpoint-3500\", num_labels = 2, \n",
    "                    \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentences(sentences):\n",
    " \n",
    "    # 평가모드로 변경!!!!!\n",
    "    model2.eval()\n",
    "\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model2(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20660742 0.5705789 ]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['기대를 하지 않고 가면 충분히 즐길만합니다.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits))  #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4956115 0.7484025]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['야간 개장을 시작하여 선선하게 둘러볼 수 있어 더 좋은 것 같다.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.629299  0.2787813]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['놀이기구 운영을 너무 천천히 해요 기구 타려면 너무 오래 기다려야 해요.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6168568  0.02267386]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['아이들의 놀이터 하지만 어른들의 새치기 주말은 피하시길다.'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.653729   0.47054613]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['좋긴 한데 사람이 너무 많아서'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.012468   0.36440152]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['동네라서 자주 가는데 갈 때마다 좋은 곳이에요 이에는 뱀이 나와서 좀 놀랐어요'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30119035 0.7184674 ]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['간단하게 발족 욕을 할 수 있는 족욕 쟁입니다 일부러 들릴만한 곳은 아니지만 쉬어가기에는 좋은 것 같네요 물을 자주 갈아주는 것 같지는 않네요'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4763077  0.30161127]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['현재 코로나 때에 물다 빠져 있고 체험 불가'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3433645  0.41356367]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['유성온천 근처의 산책과 함께 족욕을 즐길 수 있는 곳 사람이 많을 때는 물이 약간 깨끗하지 않음'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #긍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.53869146 0.4992556 ]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "logits = test_sentences(['산책로가 잘되어 있어 산책하기 좋습니다 등산로도 있는데 등산하신다면 신발과 배낭 그리고 물은 챙기시는 게 좋을 거 같습니다 등산로 지형은 간혹 가파른 곳이 있어 안전사고에 주의가 필요합니다'])\n",
    "\n",
    "print(logits)\n",
    "print(np.argmax(logits)) #부"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
